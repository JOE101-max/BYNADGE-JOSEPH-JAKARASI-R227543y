From google.colab import drive
mount.drive("/content/drive")
#  INSTALL LIBRARIES (TEXT ONLY)
!pip install -q pdfminer.six bertopic transformers sentence-transformers \
                scikit-learn gensim umap-learn hdbscan python-docx
# IMPORTANT: Install google.colab only if running in a Colab environment
try:
    from google.colab import files
except ImportError:
    print("google.colab not available. Download functionality will be skipped.")
    # Define a dummy function if not in Colab
    class FilesMock:
        def download(self, path):
            print(f"File saved locally at: {path}")
    files = FilesMock()
#  IMPORTS

import os, time, warnings
import numpy as np
from pdfminer.high_level import extract_text
from bertopic import BERTopic
from umap import UMAP
from hdbscan import HDBSCAN
from transformers import pipeline
from sentence_transformers import SentenceTransformer
from gensim.corpora.dictionary import Dictionary
from gensim.models.coherencemodel import CoherenceModel
from docx import Document

warnings.filterwarnings("ignore")

PDF_FILE_PATH = "/content/drive/MyDrive/NLP/pdf_files/merged_document.pdf"
OUTPUT_PATH = "Deep_Learning_Text_Report_V3.docx"

MAX_DOCS = 2200              
MAX_SUMMARY_CHUNKS = 50      
EMBED_BATCH = 64
TOP_N_TOPICS_FOR_INSIGHTS = 8
MIN_CLUSTER_SIZE = 20

# Time Budget
start_time = time.time()
TARGET_MINUTES = 25
MAX_SECONDS = TARGET_MINUTES * 60

# Check GPU
try:
    import torch
    device = 0 if torch.cuda.is_available() else -1
except ImportError:
    device = -1

print(f"Device: {'GPU' if device == 0 else 'CPU'}")
print(f"Target Runtime: {TARGET_MINUTES} minutes (Maximum Quality).")

def time_ok():
    return (time.time() - start_time) < MAX_SECONDS

